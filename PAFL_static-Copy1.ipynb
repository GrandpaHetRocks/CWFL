{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7091deeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.965368670501988, 14.198524584141133, 16.39857923621766, 16.474607037533215, 16.64053451779476, 16.815237373592854, 17.20801937719735, 17.315058668214707, 17.339557837684723, 17.46164374170204, 17.493970325578022, 17.58902537963803, 18.060312641770285, 18.26073255324264, 18.52738285206238, 18.59634684401101, 18.78586594003834, 18.87429354229012, 18.874848753130173, 19.163813889663786, 19.329395308160638, 19.423005545935663, 19.50441469492017, 19.522413079489905, 19.546685886253346, 19.795884466622628, 20.117584186465088, 20.170186178607064, 20.345741071576082, 20.408499355937554, 20.896676814050213, 20.90823329068409, 21.065780704646023, 21.35720750307468, 21.90220238527388, 21.964306914099954, 21.968012648610014, 21.96822864513934, 22.183479767507254, 22.424694880388838, 22.691402595907345, 22.831830100355376, 23.64608126010971, 23.80079164476615, 24.55089958386886, 24.97218942487701, 26.133817214136037, 26.272645323739965, 28.980342769299103]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import numpy as np\n",
    "from Dataset import load_dataset, getImage\n",
    "from utils import averageModels\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from no_cluster import get_cluster\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2519aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.seed(15)\n",
    "P=2 #signal power threshold\n",
    "#stream = BitStream()\n",
    "key=[]\n",
    "for i in range (10000): #generating a random password to activate training (Pilot signal)\n",
    "    temp=random.randint(0,1)\n",
    "    key.append(temp)\n",
    "\n",
    "key1=[0]*len(key)\n",
    "for i in range (len(key)):   #bpsk modulation\n",
    "    if(key[i]==1):\n",
    "        #print(\"yay\")\n",
    "        key1[i]=-math.sqrt(P)\n",
    "    else:\n",
    "        key1[i]=math.sqrt(P)\n",
    "\n",
    "#print(key)\n",
    "        \n",
    "key_np=np.array(key1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e1f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 10000\n",
    "        self.clients = 50\n",
    "        self.rounds = 200\n",
    "        self.epochs = 5\n",
    "        self.local_batches = 64\n",
    "        self.lr = 0.0001\n",
    "        self.C = 0.9 #fraction of clients used in the round\n",
    "        self.drop_rate = 0.1 #fraction of devices in the selected set to be dropped for various reasons\n",
    "        self.torch_seed = 0 #same weights and parameters whenever the program is run\n",
    "        self.log_interval = 64\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = False\n",
    "        self.save_model = True\n",
    "        self.csi_low=0\n",
    "        self.csi_high=1\n",
    " \n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2045bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if gpu is available\n",
    "use_cuda = False\n",
    "#print(use_cuda)\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "#generating virtual clients\n",
    "for i in range(int(args.clients)):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})\n",
    "    \n",
    "global_train, global_test, train_group, test_group = load_dataset(args.clients, args.iid) #load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ceaf407",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inx, client in enumerate(clients):  #return actual image set for each client\n",
    "    trainset_ind_list = list(train_group[inx]) \n",
    "    client['trainset'] = getImage(global_train, trainset_ind_list, args.local_batches)\n",
    "    client['testset'] = getImage(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(trainset_ind_list) / args.images #useful while taking weighted average\n",
    "\n",
    "#load dataset for global model (to compare accuracies)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "global_test_dataset = datasets.FashionMNIST('./', train=True, download=True, transform=transform)\n",
    "global_test_dataset = torch.utils.data.random_split(global_test_dataset, [10000, len(global_test_dataset)-10000])[0]\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d020db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.quant = torch.quantization.QuantStub()\n",
    "        self.conv1 = nn.Conv2d(1, 5, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(5, 10, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*10, 128)  #10 iid 50 non iid\n",
    "        self.fc2 = nn.Linear(128, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x=self.quant(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.quant = torch.quantization.QuantStub()\n",
    "        self.conv1 = nn.Conv2d(1, 5, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(5, 10, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*10, 50) #10 iid #50 non iid\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x=self.quant(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*10\n",
    "                   )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b696a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client,key_np,key,snr,csi,mu):\n",
    "    gc=False\n",
    "    client['model'].train()\n",
    "    #simulating a wireless channel\n",
    "    poptim=max((1/mu-1/csi),0)\n",
    "    #print(mu,csi)\n",
    "    print(\"Power Allocated=\",poptim)\n",
    "    print(\"CSI=\",csi)\n",
    "    \n",
    "    snr__=10**(snr/10)\n",
    "    \n",
    "    absh=csi*poptim/snr__\n",
    "    x=random.uniform(0,absh)\n",
    "    #print(x)\n",
    "    y=math.sqrt(absh*absh-x*x)\n",
    "    #x=x*100\n",
    "    #y=y*100\n",
    "    #x=random.random()\n",
    "    #y=random.random()\n",
    "    #snr=10*math.log(poptim/(std*std),10)\n",
    "    std=math.sqrt(poptim/snr__*absh*absh) #channel noise\n",
    "    \n",
    "    #print(x,y)\n",
    "    h=complex(x,y)\n",
    "    #std=math.sqrt(abs(h)/csi)\n",
    "    #snr=poptim/(std*std)\n",
    "    #print(std)\n",
    "    print(\"SNR=\",snr)\n",
    "    #print(\"csi\",abs(h)/(std*std))\n",
    "    \n",
    "    \n",
    "    if(poptim!=0):\n",
    "        data=client['model'].conv1.weight\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        #print(power)\n",
    "        data=h*data+(torch.randn(data.size())*std) #channel affecting data\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv1.weight.data=data\n",
    "        \n",
    "        \n",
    "        \n",
    "        data=client['model'].conv2.weight\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        data=h*data+(torch.randn(data.size())*std) #channel affecting data\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv2.weight.data=data\n",
    "\n",
    "    \n",
    "    #print(client['model'].conv1.weight.size)\n",
    "    client['model'].send(client['hook'])\n",
    "    print(\"Client:\",client['hook'].id)\n",
    "    \n",
    "    key_np_received=h*key_np+(np.random.randn(len(key_np))*std*2)\n",
    "    #print(key_np_received)\n",
    "    key_np_received=(key_np_received/(h)).real\n",
    "    \n",
    "    for o in range (len(key_np_received)):  #demodulation bpsk\n",
    "        if(key_np_received[o]>=0):\n",
    "            key_np_received[o]=0\n",
    "        else:\n",
    "            key_np_received[o]=1\n",
    "    \n",
    "    key_np_received=key_np_received.tolist()\n",
    "    key_np_received = [int(item) for item in key_np_received]\n",
    "    #key_np=key_np.tolist()\n",
    "    \n",
    "    \n",
    "    if(sum(np.bitwise_xor(key,key_np_received))/len(key)==0 and poptim>0): #...............................................checking if channel is good enough for transmission by checking BER..................................#\n",
    "        gc=True #considering the client model for training\n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            for batch_idx, (data, target) in enumerate(client['trainset']): \n",
    "                data,target=data,target\n",
    "                data = data.send(client['hook'])\n",
    "                target = target.send(client['hook'])\n",
    "                \n",
    "                #train model on client\n",
    "                data, target = data.to(device), target.to(device) #send data to cpu/gpu (data is stored locally)\n",
    "                output = client['model'](data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                client['optim'].step()\n",
    "                \n",
    "                if batch_idx % args.log_interval == 0:\n",
    "                    loss = loss.get() \n",
    "                    print('Model {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        client['hook'].id,\n",
    "                        epoch, batch_idx * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                        100. * batch_idx / len(client['trainset']), loss))\n",
    "    else:\n",
    "        print(\"Poor Channel, client not taken for averaging in this round\")\n",
    "            \n",
    "                    \n",
    "    client['model'].get() \n",
    "    #CHANGE\n",
    "    if(poptim!=0):\n",
    "        data=client['model'].conv1.weight\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        #print(power)\n",
    "        data=h*data+(torch.randn(data.size())*std) #channel affecting data\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv1.weight.data=data\n",
    "        \n",
    "        \n",
    "        \n",
    "        data=client['model'].conv2.weight\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        data=h*data+(torch.randn(data.size())*std) #channel affecting data\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv2.weight.data=data\n",
    "    #CHANGE ENDS\n",
    "    print()\n",
    "    return gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07333629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()    #no need to train the model while testing\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if(use_cuda):\n",
    "                data,target=data.cuda(),target.cuda()\n",
    "                #model.cuda()\n",
    "            else:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return(100. * correct / len(test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5192831",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "#global_model = Net() #redundant code as we don't use it for training: assigns a CNN to the global model\n",
    "\n",
    "for client in clients: #give the model and optimizer to every client\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    #client['model'] = torch.quantization.quantize_dynamic(\n",
    "    #client['model'],  # the original model\n",
    "    #{torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "    #dtype=torch.fp)  # the target dtype for quantized weights\n",
    "    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr)\n",
    "    \n",
    "\n",
    "accuracy=[]\n",
    "rc=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19786553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.905215350651497, 12.716400799267944, 13.401434657941557, 13.507184173247428, 13.608461677332944, 13.6562775705455, 13.90888868153556, 13.980457862681842, 14.02213471572457, 14.066734458079488, 14.21342568656538, 14.257307521356893, 14.31548391640263, 14.504677735946316, 14.631435097078251, 15.073856287809308, 15.078933270854098, 15.13036185128102, 15.138351682701373, 15.167002557569207, 15.580682759965336, 15.712016058285958, 16.044578630963308, 16.07407763669414, 16.196467581773973, 16.302092346189966, 16.31296480955878, 16.3782113220841, 16.53547407258474, 17.228811537313174, 17.3469563663908, 17.446611312434516, 17.712032986630383, 17.799678593397676, 17.932836639375193, 18.190668086062946, 18.38097198252857, 18.435716842616436, 18.546828066045887, 18.621263210183173, 18.652003021794314, 18.708755644321275, 18.71989346711673, 19.680035596903046, 20.192065056103004, 20.441162288952324, 20.565544387022324, 21.288441403091813, 23.1195154867615]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power Allocated= 3.163885130065338\n",
      "CSI= 0.9192734924680099\n",
      "SNR= 10.905215350651497\n",
      "Client: client1\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.09447689053098185\n",
      "SNR= 12.716400799267944\n",
      "Client: client2\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.03682641150636046\n",
      "SNR= 13.401434657941557\n",
      "Client: client3\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 1.8008712308002743\n",
      "CSI= 0.40802512807054847\n",
      "SNR= 13.507184173247428\n",
      "Client: client4\n",
      "Model client4 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.344599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32836/1844779813.py:57: RuntimeWarning: invalid value encountered in true_divide\n",
      "  key_np_received=(key_np_received/(h)).real\n",
      "/home/iiitd/.local/lib/python3.8/site-packages/syft/frameworks/torch/hook/hook.py:560: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n",
      "/home/iiitd/.local/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/native.py:156: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  to_return = self.native_grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model client4 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.328866\n",
      "Model client4 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.323062\n",
      "Model client4 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.314906\n",
      "Model client4 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.307870\n",
      "\n",
      "Power Allocated= 3.1409130270162393\n",
      "CSI= 0.9002620771562061\n",
      "SNR= 13.608461677332944\n",
      "Client: client5\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0.004056256864189756\n",
      "CSI= 0.2354246025135942\n",
      "SNR= 13.6562775705455\n",
      "Client: client6\n",
      "Model client6 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.305581\n",
      "Model client6 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.362539\n",
      "Model client6 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.345949\n",
      "Model client6 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.281359\n",
      "Model client6 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.280491\n",
      "\n",
      "Power Allocated= 2.682812013729274\n",
      "CSI= 0.6373938580379257\n",
      "SNR= 13.90888868153556\n",
      "Client: client7\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 2.8658606212701203\n",
      "CSI= 0.7215839905218395\n",
      "SNR= 13.980457862681842\n",
      "Client: client8\n",
      "Model client8 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.332698\n",
      "Model client8 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.290324\n",
      "Model client8 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.331611\n",
      "Model client8 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.304722\n",
      "Model client8 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.298630\n",
      "\n",
      "Power Allocated= 2.4694080116864128\n",
      "CSI= 0.5610750790964535\n",
      "SNR= 14.02213471572457\n",
      "Client: client9\n",
      "Model client9 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.320006\n",
      "Model client9 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.312332\n",
      "Model client9 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.309586\n",
      "Model client9 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.309489\n",
      "Model client9 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.295560\n",
      "\n",
      "Power Allocated= 1.8889121564490066\n",
      "CSI= 0.42322873584207343\n",
      "SNR= 14.066734458079488\n",
      "Client: client10\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 3.155071469248703\n",
      "CSI= 0.911885247946626\n",
      "SNR= 14.21342568656538\n",
      "Client: client11\n",
      "Model client11 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.342658\n",
      "Model client11 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.324243\n",
      "Model client11 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.295128\n",
      "Model client11 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.316080\n",
      "Model client11 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.304538\n",
      "\n",
      "Power Allocated= 2.910418745981432\n",
      "CSI= 0.7455554081763619\n",
      "SNR= 14.257307521356893\n",
      "Client: client12\n",
      "Model client12 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.406353\n",
      "Model client12 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.304359\n",
      "Model client12 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.342802\n",
      "Model client12 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.286313\n",
      "Model client12 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.270491\n",
      "\n",
      "Power Allocated= 2.591666226108162\n",
      "CSI= 0.6023971354879897\n",
      "SNR= 14.31548391640263\n",
      "Client: client13\n",
      "Model client13 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.341582\n",
      "Model client13 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.335269\n",
      "Model client13 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.291497\n",
      "Model client13 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.206080\n",
      "Model client13 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.246151\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.009778956667922833\n",
      "SNR= 14.504677735946316\n",
      "Client: client14\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 2.3953544389766703\n",
      "CSI= 0.5386926090371565\n",
      "SNR= 14.631435097078251\n",
      "Client: client15\n",
      "Model client15 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.402532\n",
      "Model client15 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.412281\n",
      "Model client15 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.306824\n",
      "Model client15 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.266911\n",
      "Model client15 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.265235\n",
      "\n",
      "Power Allocated= 3.1526266650401005\n",
      "CSI= 0.9098568305142741\n",
      "SNR= 15.073856287809308\n",
      "Client: client16\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.11657746856098683\n",
      "SNR= 15.078933270854098\n",
      "Client: client17\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 3.244299636153106\n",
      "CSI= 0.9926533289173625\n",
      "SNR= 15.13036185128102\n",
      "Client: client18\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 2.87480910597907\n",
      "CSI= 0.7262735996573452\n",
      "SNR= 15.138351682701373\n",
      "Client: client19\n",
      "Model client19 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.325530\n",
      "Model client19 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.345101\n",
      "Model client19 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.347610\n",
      "Model client19 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.306533\n",
      "Model client19 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.294714\n",
      "\n",
      "Power Allocated= 1.6281077259934107\n",
      "CSI= 0.381156687575706\n",
      "SNR= 15.167002557569207\n",
      "Client: client20\n",
      "Model client20 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.319949\n",
      "Model client20 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.300189\n",
      "Model client20 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.303581\n",
      "Model client20 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.318732\n",
      "Model client20 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.271687\n",
      "\n",
      "Power Allocated= 2.6770321848001943\n",
      "CSI= 0.6350543005561459\n",
      "SNR= 15.580682759965336\n",
      "Client: client21\n",
      "Model client21 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.350762\n",
      "Model client21 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.316610\n",
      "Model client21 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.313738\n",
      "Model client21 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.331542\n",
      "Model client21 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.309702\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.0677399222602505\n",
      "SNR= 15.712016058285958\n",
      "Client: client22\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.1327754645977025\n",
      "SNR= 16.044578630963308\n",
      "Client: client23\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 3.073270948189216\n",
      "CSI= 0.848586871812971\n",
      "SNR= 16.07407763669414\n",
      "Client: client24\n",
      "Model client24 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.343428\n",
      "Model client24 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.317799\n",
      "Model client24 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.324877\n",
      "Model client24 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.287685\n",
      "Model client24 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.293766\n",
      "\n",
      "Power Allocated= 0.9776358839030834\n",
      "CSI= 0.3054307297488047\n",
      "SNR= 16.196467581773973\n",
      "Client: client25\n",
      "Model client25 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.359085\n",
      "Model client25 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.306457\n",
      "Model client25 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.325723\n",
      "Model client25 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.309548\n",
      "Model client25 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.306346\n",
      "\n",
      "Power Allocated= 1.7391170730325816\n",
      "CSI= 0.39799670630601647\n",
      "SNR= 16.302092346189966\n",
      "Client: client26\n",
      "Model client26 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.308244\n",
      "Model client26 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.324756\n",
      "Model client26 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.301589\n",
      "Model client26 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.302520\n",
      "Model client26 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.288581\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.04302526179657562\n",
      "SNR= 16.31296480955878\n",
      "Client: client27\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.07989125928762775\n",
      "SNR= 16.3782113220841\n",
      "Client: client28\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 2.3180720264109\n",
      "CSI= 0.5171623817235519\n",
      "SNR= 16.53547407258474\n",
      "Client: client29\n",
      "Model client29 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.315395\n",
      "Model client29 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.312870\n",
      "Model client29 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.317963\n",
      "Model client29 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.315392\n",
      "Model client29 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.283320\n",
      "\n",
      "Power Allocated= 3.1663557347172784\n",
      "CSI= 0.9213660634761469\n",
      "SNR= 17.228811537313174\n",
      "Client: client30\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.10403607122443326\n",
      "SNR= 17.3469563663908\n",
      "Client: client31\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 2.6538711411139966\n",
      "CSI= 0.6258489879506259\n",
      "SNR= 17.446611312434516\n",
      "Client: client33\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 3.0030340198590864\n",
      "CSI= 0.8008542485380931\n",
      "SNR= 17.712032986630383\n",
      "Client: client34\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 2.901641664166226\n",
      "CSI= 0.7407083602049289\n",
      "SNR= 17.799678593397676\n",
      "Client: client35\n",
      "Model client35 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.361274\n",
      "Model client35 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.349693\n",
      "Model client35 Train Epoch: 3 [0/1216 (0%)]\tLoss: 2.310921\n",
      "Model client35 Train Epoch: 4 [0/1216 (0%)]\tLoss: 2.311795\n",
      "Model client35 Train Epoch: 5 [0/1216 (0%)]\tLoss: 2.296286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32836/1320575217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mgoodchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mClientUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmallmu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoodchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mclient_good_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32836/1844779813.py\u001b[0m in \u001b[0;36mClientUpdate\u001b[0;34m(args, device, client, key_np, key, snr, csi, mu)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m#train model on client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#send data to cpu/gpu (data is stored locally)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32836/1838802884.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         x = x.view(-1, 4*4*10\n\u001b[1;32m     37\u001b[0m                    )\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FL/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;31m# Change the library path to avoid errors on layers like AvgPooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/syft/generic/pointers/object_pointer.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# Send the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mcmd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# Step 1: serialize the message to a binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mbin_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj, worker, simplified, force_full_simplification, strategy)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsgpack_serialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_full_simplification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fed_round in range(args.rounds):\n",
    "    \n",
    "    client_good_channel=[] #to check which clients have a good channel, only those will be taken for averaging per round\n",
    "\n",
    "    # Training \n",
    "    #even slot\n",
    "    \n",
    "    snr=[] #snr of the channel\n",
    "    csi=[] #csi of the channel\n",
    "    for ii in range (int(args.clients)-1):\n",
    "        #snr.append(random.uniform(args.snr_low, args.snr_high))\n",
    "        csi.append(random.uniform(args.csi_low,args.csi_high))\n",
    "    \n",
    "    # if(fed_round==0):\n",
    "    #     snr,cluster_head=get_cluster()\n",
    "    if(fed_round==0): #fed_round==0 or True                                        %%%static or moving\n",
    "        snr,cluster_head=get_cluster()\n",
    "        temp=copy.deepcopy(cluster_head)\n",
    "        temp1=copy.deepcopy(snr)\n",
    "    else:\n",
    "        #print(temp)\n",
    "        cluster_head=copy.deepcopy(temp)\n",
    "        snr=copy.deepcopy(temp1)\n",
    "    #print(cluster_head)\n",
    "    smallmu1=0\n",
    "    gsmall1=3.402823466E+38 \n",
    "    \n",
    "    #water filling algorithm\n",
    "    mu=1e-15\n",
    "    while(mu<=1):\n",
    "        #print(\"yay\")\n",
    "        #pn=max(1/mu-1/csi,0)\n",
    "        g1=0\n",
    "        pn1=0\n",
    "        for jj in csi:\n",
    "            pn=max(1/mu-1/jj,0)\n",
    "            g1+=math.log(1+pn*jj) #capacity of a channel (shannon's law)\n",
    "            pn1+=pn\n",
    "        g=g1-mu*(pn1-P*(int(args.clients)-1))\n",
    "        if(g<gsmall1):\n",
    "            smallmu1=mu\n",
    "            gsmall1=g\n",
    "        mu+=0.00002\n",
    "\n",
    "    #print(smallmu1)\n",
    "    # poptim=max(1/smallmu1-1/csi1,0)\n",
    "    # print(poptim)\n",
    "    index=0\n",
    "    members=[]\n",
    "    for i in clients:\n",
    "        if(i['hook'].id!=cluster_head):\n",
    "            members.append(i)\n",
    "        else:\n",
    "            head=i\n",
    "    for client in members:\n",
    "        goodchannel=ClientUpdate(args, device, client,key_np,key,snr[index],csi[index],smallmu1)\n",
    "        if(goodchannel):\n",
    "            client_good_channel.append(client)\n",
    "        index+=1\n",
    "        \n",
    "    po=[]    \n",
    "    for jj in csi:\n",
    "        po.append(max(1/smallmu1-1/jj,0))\n",
    "    \n",
    "    plt.bar([str(i) for i in range (1,len(po)+1)],po,)\n",
    "    csi.sort()\n",
    "    po=[]\n",
    "    for jj in csi:\n",
    "        po.append(max(1/smallmu1-1/jj,0))\n",
    "    fig,ax=plt.subplots()\n",
    "    line1=ax.plot(csi,po,label=\"channel power allocated\")\n",
    "    line2=ax.plot(csi,[1/smallmu1]*len(csi),label=\"maximum power allocated\")\n",
    "    ax.set_title(\"csi vs power allocated\")\n",
    "    ax.set_xlabel(\"csi (channel gain to noise ratio)\")\n",
    "    ax.set_ylabel(\"power allocated\")\n",
    "    ax.legend()\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "#     # Testing \n",
    "#     for client in active_clients:\n",
    "#         test(args, client['model'], device, client['testset'], client['hook'].id)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print(\"Clients having a good channel and considered for training\")\n",
    "    for no in range (len(client_good_channel)):\n",
    "        print(client_good_channel[no]['hook'].id)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Averaging \n",
    "        #odd slot\n",
    "\n",
    "    head['model'] = averageModels(head['model'],client_good_channel)\n",
    "    # Testing the average model\n",
    "    #test(args, global_model, device, global_test_loader, 'Global')\n",
    "    ac=test(args, head['model'], device, global_test_loader, 'Final')\n",
    "    accuracy.append(ac)\n",
    "    \n",
    "    print(\"Power in training Round=\",sum(po))\n",
    "    #print(\"Power cap=\",P*len(active_clients))\n",
    "    \n",
    "    #print(\"Total Power =\",power_odd+power_even)\n",
    "    print()\n",
    "            \n",
    "    # Share the global model with the clients\n",
    "    index=0\n",
    "    for client in members:\n",
    "        client['model'].load_state_dict(head['model'].state_dict())\n",
    "        #client=CLientReturn(client,snr[index],csi[index],smallmu1) #CHANGE:Commented\n",
    "        index+=1\n",
    "        #client['model']=torch.quantization.quantize_dynamic(client['model'],{torch.nn.Conv2d},dtype=torch.qint8)\n",
    "        #print(client['model'].conv1.weight.data)\n",
    "    fig1,ax1=plt.subplots()\n",
    "    ax1.plot([i for i in range(len(accuracy))],accuracy)\n",
    "    plt.show()\n",
    "    print(rc)\n",
    "    rc+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FL",
   "language": "python",
   "name": "fl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
