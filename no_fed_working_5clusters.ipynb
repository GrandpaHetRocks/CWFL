{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import numpy as np\n",
    "from Dataset import load_dataset, getImage\n",
    "from utils import averageModels\n",
    "from utils import averageModelscluster\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.K_clusters import cluster_former\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=2 #signal power threshold\n",
    "#stream = BitStream()\n",
    "#random.seed(10)\n",
    "key=[]\n",
    "for i in range (10000): #generating a random password to activate training (Pilot signal)\n",
    "    temp=random.randint(0,1)\n",
    "    key.append(temp)\n",
    "\n",
    "key1=[0]*len(key)\n",
    "for i in range (len(key)):   #bpsk modulation\n",
    "    if(key[i]==1):\n",
    "        #print(\"yay\")\n",
    "        key1[i]=-math.sqrt(P)\n",
    "    else:\n",
    "        key1[i]=math.sqrt(P)\n",
    "\n",
    "#print(key)\n",
    "        \n",
    "key_np=np.array(key1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 10000\n",
    "        self.clients = 50\n",
    "        self.rounds = 200\n",
    "        self.epochs = 5\n",
    "        self.local_batches = 64\n",
    "        self.lr = 0.01\n",
    "        self.C = 1 #fraction of clients used in the round\n",
    "        self.drop_rate = 0 #fraction of devices in the selected set to be dropped for various reasons\n",
    "        self.torch_seed = 0 #same weights and parameters whenever the program is run\n",
    "        self.log_interval = 64\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = False\n",
    "        self.save_model = True\n",
    "        self.numclusters=5\n",
    "\n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if gpu is available\n",
    "#use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "use_cuda=False\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "me = hook.local_worker\n",
    "clients = []\n",
    "\n",
    "#generating virtual clients\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})\n",
    "#print(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train, global_test, train_group, test_group = load_dataset(args.clients, args.iid) #load data\n",
    "\n",
    "for inx, client in enumerate(clients):  #return actual image set for each client\n",
    "    trainset_ind_list = list(train_group[inx]) \n",
    "    client['trainset'] = getImage(global_train, trainset_ind_list, args.local_batches)\n",
    "    client['testset'] = getImage(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(trainset_ind_list) / args.images #useful while taking weighted average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset for global model (to compare accuracies)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "global_test_dataset = datasets.MNIST('./', train=False, download=True, transform=transform)\n",
    "# global_test_dataset = torch.utils.data.random_split(global_test_dataset, [10000, len(global_test_dataset)-10000])[0]\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.quant = torch.quantization.QuantStub()\n",
    "        self.conv1 = nn.Conv2d(1, 5, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(5, 10, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*10, 50) #10 iid #50 non iid\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x=self.quant(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*10\n",
    "                   )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1) \"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedprox(params,global_params):\n",
    "    global_param=[]\n",
    "    ind=0\n",
    "    for gp in global_params:\n",
    "        global_param.append(gp)\n",
    "    for p in params:\n",
    "    #                 print(p.grad)\n",
    "        lr=0.001\n",
    "        mu=0.1\n",
    "        if(p.grad is None):\n",
    "            continue\n",
    "        grad=p.grad.data #batch gradients\n",
    "        p.data.sub_(lr,(grad+mu*(p.data.clone()-global_param[ind].data.clone())))\n",
    "        ind+=1\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client,key_np,key,snr,csi,mu,head):\n",
    "    gc=False\n",
    "    client['model'].train()\n",
    "    #simulating a wireless channel\n",
    "    poptim=max((1/mu-1/csi),0)\n",
    "    #print(mu,csi)\n",
    "    print(\"Power Allocated=\",poptim)\n",
    "    print(\"CSI=\",csi)\n",
    "    \n",
    "    snr__=10**(snr/10)\n",
    "    \n",
    "    absh=csi*poptim/snr__\n",
    "    x=random.uniform(0,absh)\n",
    "    #print(x)\n",
    "    y=math.sqrt(absh*absh-x*x)\n",
    "    #x=x*100\n",
    "    #y=y*100\n",
    "    #x=random.random()\n",
    "    #y=random.random()\n",
    "    #snr=10*math.log(poptim/(std*std),10)\n",
    "    std=math.sqrt(poptim/snr__*absh*absh) #channel noise\n",
    "    \n",
    "    #print(x,y)\n",
    "    h=complex(x,y)\n",
    "    #std=math.sqrt(abs(h)/csi)\n",
    "    #snr=poptim/(std*std)\n",
    "    #print(std)\n",
    "    print(\"SNR=\",snr)\n",
    "    #print(\"csi\",abs(h)/(std*std))\n",
    "    \n",
    "    \n",
    "    if(poptim!=0):\n",
    "        data=client['model'].conv1.weight\n",
    "        #data=data.cuda()\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        #print(power)\n",
    "        if(use_cuda):\n",
    "            data=h*data+(torch.randn(data.size())*std).cuda() #channel affecting data\n",
    "        else:\n",
    "            data=h*data+(torch.randn(data.size())*std)\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv1.weight.data=data\n",
    "        \n",
    "        \n",
    "        \n",
    "        data=client['model'].conv2.weight\n",
    "        #data=data.cuda()\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        if(use_cuda):\n",
    "            data=h*data+(torch.randn(data.size())*std).cuda() #channel affecting data\n",
    "        else:\n",
    "            data=h*data+(torch.randn(data.size())*std)\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv2.weight.data=data\n",
    "\n",
    "    \n",
    "    #print(client['model'].conv1.weight.size)\n",
    "    client['model'].send(client['hook'])\n",
    "    head['model'].send(client['hook'])\n",
    "    print(\"Client:\",client['hook'].id)\n",
    "    \n",
    "    key_np_received=h*key_np+(np.random.randn(len(key_np))*std*2)\n",
    "    #print(key_np_received)\n",
    "    key_np_received=(key_np_received/(h)).real\n",
    "    \n",
    "    for o in range (len(key_np_received)):  #demodulation bpsk\n",
    "        if(key_np_received[o]>=0):\n",
    "            key_np_received[o]=0\n",
    "        else:\n",
    "            key_np_received[o]=1\n",
    "    \n",
    "    key_np_received=key_np_received.tolist()\n",
    "    key_np_received = [int(item) for item in key_np_received]\n",
    "    #key_np=key_np.tolist()\n",
    "    \n",
    "    \n",
    "    if(sum(np.bitwise_xor(key,key_np_received))/len(key)==0 and poptim>0): #...............................................checking if channel is good enough for transmission by checking BER..................................#\n",
    "        gc=True #considering the client model for training\n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            for batch_idx, (data, target) in enumerate(client['trainset']): \n",
    "                data = data.send(client['hook'])\n",
    "                target = target.send(client['hook'])\n",
    "                #client['optim'].zero_grad()\n",
    "                #train model on client\n",
    "                data, target = data.to(device), target.to(device) #send data to cpu/gpu (data is stored locally)\n",
    "                output = client['model'](data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                client['optim'].step()\n",
    "                params=client['model'].parameters()\n",
    "                gp=head['model'].parameters()\n",
    "                #params=fedprox(params,gp) \n",
    "                \n",
    "                if batch_idx % args.log_interval == 0:\n",
    "                    loss = loss.get() \n",
    "                    print('Model {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        client['hook'].id,\n",
    "                        epoch, batch_idx * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                        100. * batch_idx / len(client['trainset']), loss))\n",
    "    else:\n",
    "        print(\"Poor Channel, client not taken for averaging in this round\")\n",
    "            \n",
    "                    \n",
    "    client['model'].get()\n",
    "    head['model'].get()\n",
    "    # print()\n",
    "         #CHANGE\n",
    "    if(poptim!=0):\n",
    "        data=client['model'].conv1.weight\n",
    "        #data=data.cuda()\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        #print(power)\n",
    "        if(use_cuda):\n",
    "            data=h*data+(torch.randn(data.size())*std).cuda() #channel affecting data\n",
    "        else:\n",
    "            data=h*data+(torch.randn(data.size())*std)\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv1.weight.data=data\n",
    "        \n",
    "        \n",
    "        \n",
    "        data=client['model'].conv2.weight\n",
    "        #data=data.cuda()\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        if(use_cuda):\n",
    "            data=h*data+(torch.randn(data.size())*std).cuda() #channel affecting data\n",
    "        else:\n",
    "            data=h*data+(torch.randn(data.size())*std)\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv2.weight.data=data\n",
    "    #CHANGE ENDS\n",
    "    print()\n",
    "    return gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name,fed_round):\n",
    "    model.eval()    #no need to train the model while testing\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if(use_cuda and fed_round==0):\n",
    "                data,target=data.cuda(),target.cuda()\n",
    "                #model.cuda()\n",
    "            else:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return([100. * correct / len(test_loader.dataset),test_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f68bc130050>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.torch_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort(neighbours,snrs):\n",
    "    ind=0\n",
    "    poptim=2\n",
    "    csi=random.random()\n",
    "    distorted_models=[]\n",
    "    for client in neighbours:\n",
    "        snr=snrs[ind]\n",
    "        ind+=1\n",
    "        snr__=10**(snr/10)\n",
    "        absh=csi*poptim/snr__\n",
    "        x=random.uniform(0,absh)\n",
    "        y=math.sqrt(absh*absh-x*x)\n",
    "        std=math.sqrt(poptim/snr__*absh*absh) #channel noise\n",
    "        h=complex(x,y)\n",
    "        data=client['model'].conv1.weight\n",
    "        #data=data.cuda()\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        #print(power)\n",
    "        if(use_cuda):\n",
    "            data=h*data+(torch.randn(data.size())*std).cuda() #channel affecting data\n",
    "        else:\n",
    "            data=h*data+(torch.randn(data.size())*std)\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv1.weight.data=data\n",
    "        \n",
    "        \n",
    "        \n",
    "        data=client['model'].conv2.weight\n",
    "        #data=data.cuda()\n",
    "        data=data*math.sqrt(poptim) #transmitted signal\n",
    "        if(use_cuda):\n",
    "            data=h*data+(torch.randn(data.size())*std).cuda() #channel affecting data\n",
    "        else:\n",
    "            data=h*data+(torch.randn(data.size())*std)\n",
    "        data=data/(math.sqrt(poptim)*(h))  #demodulating received data\n",
    "        data=data.real #demodulating received data\n",
    "        client['model'].conv2.weight.data=data\n",
    "        \n",
    "        distorted_models.append(client)\n",
    "    return(distorted_models)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decentralized(clients,snrs,weights):\n",
    "    big_daddy_of_distorted_models=[]\n",
    "    for client in clients:\n",
    "        distorted_models=[]\n",
    "        snr_list=[]\n",
    "        for snr in snrs:\n",
    "            if(client['hook'].id in snr):\n",
    "                snr_list.append(snr[2])\n",
    "        neighbours_c = [x for x in clients if x != client]\n",
    "        neighbours={}\n",
    "        jjj=[jkl for jkl in range(len(neighbours_c))]\n",
    "        \n",
    "        dictionary = dict(zip(jjj, neighbours_c))\n",
    "        #for jjj in range(len(neighbours_c)):\n",
    "        #   neighbours[jjj].append(neighbours_c[jjj])\n",
    "        distorted_models=distort(neighbours,snr_list)\n",
    "        distorted_models.append(client)\n",
    "        big_daddy_of_distorted_models.append(distorted_models)\n",
    "    \n",
    "    \n",
    "    weight_final1=[]\n",
    "    for oho in big_daddy_of_distorted_models:\n",
    "        weight_final=[]\n",
    "        for comeon in oho:\n",
    "            for w in weights:\n",
    "                if(comeon['hook'].id==w[0]):\n",
    "                    weight_final.append(w[1])\n",
    "        weight_final1.append(weight_final)\n",
    "    \n",
    "    final_heads=[]\n",
    "    nets=[]\n",
    "    ind=0\n",
    "    for client in clients:\n",
    "        for oof in big_daddy_of_distorted_models:\n",
    "            if(client==oof[0]):\n",
    "#                 print(client)\n",
    "#                 print(\"shut up\")\n",
    "#                 print(distorted_models)\n",
    "#                 print(\"shut up\")\n",
    "#                 print(weight_final1)\n",
    "                \n",
    "                overall=Net()\n",
    "                overall=averageModelscluster(overall,distorted_models,weight_final1[ind])\n",
    "                client['model'].load_state_dict(overall.state_dict())\n",
    "                ind+=1\n",
    "                final_heads.append(client)\n",
    "                nets.append(overall)\n",
    "    \n",
    "    return(final_heads,nets)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03182000000000004\n",
      "Power Allocated= 30.319004039319548\n",
      "CSI= 0.9027131801533897\n",
      "SNR= 28.361268656477005\n",
      "Client: client1\n",
      "Model client1 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.315109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:560: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n",
      "/home/test/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py:414: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  response = command_method(*args_, **kwargs_)\n",
      "/home/test/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py:156: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  to_return = self.native_grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model client1 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.208775\n",
      "Model client1 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.717468\n",
      "Model client1 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.250332\n",
      "Model client1 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.049046\n",
      "\n",
      "Power Allocated= 29.68953329007719\n",
      "CSI= 0.5756249355127216\n",
      "SNR= 38.57682721057814\n",
      "Client: client35\n",
      "Model client35 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.320533\n",
      "Model client35 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.220878\n",
      "Model client35 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.495065\n",
      "Model client35 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.054173\n",
      "Model client35 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.329036\n",
      "\n",
      "\n",
      "Test set: Average loss for Cluster1 model: 2.2866, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "0.06856000000000065\n",
      "Power Allocated= 12.498651562501017\n",
      "CSI= 0.4791308034704841\n",
      "SNR= 26.983764733458656\n",
      "Client: client2\n",
      "Model client2 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.322849\n",
      "Model client2 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.234612\n",
      "Model client2 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.508359\n",
      "Model client2 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.240041\n",
      "Model client2 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.146435\n",
      "\n",
      "Power Allocated= 7.809239770757236\n",
      "CSI= 0.14756826992404348\n",
      "SNR= 26.193143027138845\n",
      "Client: client20\n",
      "Model client20 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.293240\n",
      "Model client20 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.209196\n",
      "Model client20 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.649730\n",
      "Model client20 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.318734\n",
      "Model client20 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.195987\n",
      "\n",
      "Power Allocated= 13.093792304038585\n",
      "CSI= 0.6702538698418233\n",
      "SNR= 25.942694013613302\n",
      "Client: client27\n",
      "Model client27 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.306212\n",
      "Model client27 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.191967\n",
      "Model client27 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.752808\n",
      "Model client27 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.216847\n",
      "Model client27 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.225060\n",
      "\n",
      "Power Allocated= 12.957608724508159\n",
      "CSI= 0.614191922877549\n",
      "SNR= 27.37509472029785\n",
      "Client: client33\n",
      "Model client33 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.294014\n",
      "Model client33 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.221975\n",
      "Model client33 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.835805\n",
      "Model client33 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.067556\n",
      "Model client33 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.282394\n",
      "\n",
      "Power Allocated= 11.334834215397121\n",
      "CSI= 0.3076042781008468\n",
      "SNR= 23.28796913122423\n",
      "Client: client36\n",
      "Model client36 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.263900\n",
      "Model client36 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.203709\n",
      "Model client36 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.199450\n",
      "Model client36 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.179750\n",
      "Model client36 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.406504\n",
      "\n",
      "Power Allocated= 2.3129131411577877\n",
      "CSI= 0.08148065902065738\n",
      "SNR= 27.774068788056006\n",
      "Client: client40\n",
      "Model client40 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.329718\n",
      "Model client40 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.228527\n",
      "Model client40 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.773614\n",
      "Model client40 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.301646\n",
      "Model client40 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.048958\n",
      "\n",
      "\n",
      "Test set: Average loss for Cluster2 model: 2.1459, Accuracy: 1837/10000 (18%)\n",
      "\n",
      "0.03186000000000004\n",
      "Power Allocated= 29.75944658113826\n",
      "CSI= 0.6142985575458751\n",
      "SNR= 32.2568837036073\n",
      "Client: client7\n",
      "Model client7 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.306873\n",
      "Model client7 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.226109\n",
      "Model client7 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.480864\n",
      "Model client7 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.230281\n",
      "Model client7 Train Epoch: 5 [0/1216 (0%)]\tLoss: 0.894413\n",
      "\n",
      "Power Allocated= 30.238590254133108\n",
      "CSI= 0.8705271356604288\n",
      "SNR= 23.436394691342848\n",
      "Client: client14\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.009082501358784967\n",
      "SNR= 29.86086489318454\n",
      "Client: client34\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.0230566797596361\n",
      "SNR= 30.45387420016102\n",
      "Client: client47\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss for Cluster3 model: 2.3013, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "0.0450999999999995\n",
      "Power Allocated= 20.718559226960426\n",
      "CSI= 0.6875735906650036\n",
      "SNR= 25.112097116782905\n",
      "Client: client3\n",
      "Model client3 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.305896\n",
      "Model client3 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.239877\n",
      "Model client3 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.533636\n",
      "Model client3 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.413617\n",
      "Model client3 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.468553\n",
      "\n",
      "Power Allocated= 19.16106324233891\n",
      "CSI= 0.332017904968712\n",
      "SNR= 29.66278945358893\n",
      "Client: client4\n",
      "Model client4 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.303332\n",
      "Model client4 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.211288\n",
      "Model client4 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.475436\n",
      "Model client4 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.004052\n",
      "Model client4 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.079586\n",
      "\n",
      "Power Allocated= 20.127663352751338\n",
      "CSI= 0.4889292604487735\n",
      "SNR= 32.934466661287566\n",
      "Client: client43\n",
      "Model client43 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.299491\n",
      "Model client43 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.200974\n",
      "Model client43 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.747496\n",
      "Model client43 Train Epoch: 4 [0/1216 (0%)]\tLoss: 0.837711\n",
      "Model client43 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.173359\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.03080727194229016\n",
      "SNR= 30.514523370682223\n",
      "Client: client46\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "\n",
      "Test set: Average loss for Cluster4 model: 2.2591, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "0.22547999999997898\n",
      "Power Allocated= 0\n",
      "CSI= 0.08253748686200335\n",
      "SNR= 19.884356433412353\n",
      "Client: client5\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0.7722934535908257\n",
      "CSI= 0.27302340184096185\n",
      "SNR= 15.916712752354083\n",
      "Client: client6\n",
      "Model client6 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.293106\n",
      "Model client6 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.211741\n",
      "Model client6 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.480381\n",
      "Model client6 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.171468\n",
      "Model client6 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.103658\n",
      "\n",
      "Power Allocated= 2.211889461650987\n",
      "CSI= 0.44982359788135173\n",
      "SNR= 36.224796912370856\n",
      "Client: client8\n",
      "Model client8 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.319186\n",
      "Model client8 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.268715\n",
      "Model client8 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.579581\n",
      "Model client8 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.149522\n",
      "Model client8 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.029054\n",
      "\n",
      "Power Allocated= 3.3161813098358515\n",
      "CSI= 0.8938133338045915\n",
      "SNR= 25.916951748692053\n",
      "Client: client9\n",
      "Model client9 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.264542\n",
      "Model client9 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.207556\n",
      "Model client9 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.501637\n",
      "Model client9 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.161888\n",
      "Model client9 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.350878\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.11552133374896467\n",
      "SNR= 19.050941470242773\n",
      "Client: client10\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0\n",
      "CSI= 0.18983668423024513\n",
      "SNR= 16.03529916261582\n",
      "Client: client11\n",
      "Poor Channel, client not taken for averaging in this round\n",
      "\n",
      "Power Allocated= 0.2253568411870992\n",
      "CSI= 0.2375507770378168\n",
      "SNR= 20.538865864210532\n",
      "Client: client12\n",
      "Model client12 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.312874\n",
      "Model client12 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.181184\n",
      "Model client12 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.487331\n",
      "Model client12 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.016117\n",
      "Model client12 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.147065\n",
      "\n",
      "Power Allocated= 1.6381756158857783\n",
      "CSI= 0.35755052460780656\n",
      "SNR= 25.762065269992277\n",
      "Client: client13\n",
      "Model client13 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.285369\n",
      "Model client13 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.180186\n",
      "Model client13 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.492642\n",
      "Model client13 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.172658\n",
      "Model client13 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.185605\n",
      "\n",
      "Power Allocated= 0.3637498839099278\n",
      "CSI= 0.2456258178695383\n",
      "SNR= 19.321771762483884\n",
      "Client: client15\n",
      "Model client15 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.295614\n",
      "Model client15 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.209806\n",
      "Model client15 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.585410\n",
      "Model client15 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.110202\n",
      "Model client15 Train Epoch: 5 [0/1216 (0%)]\tLoss: 0.956400\n",
      "\n",
      "Power Allocated= 3.185849435550659\n",
      "CSI= 0.8005548091309805\n",
      "SNR= 16.144324377628422\n",
      "Client: client17\n",
      "Model client17 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.291731\n",
      "Model client17 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.208621\n",
      "Model client17 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.637269\n",
      "Model client17 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.497590\n",
      "Model client17 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.473649\n",
      "\n",
      "Power Allocated= 3.321360705707587\n",
      "CSI= 0.8979704097751237\n",
      "SNR= 22.218681424096125\n",
      "Client: client18\n",
      "Model client18 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.300781\n",
      "Model client18 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.218157\n",
      "Model client18 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.809995\n",
      "Model client18 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.337861\n",
      "Model client18 Train Epoch: 5 [0/1216 (0%)]\tLoss: 1.201338\n",
      "\n",
      "Power Allocated= 2.0478862390841996\n",
      "CSI= 0.4189188954402816\n",
      "SNR= 19.178761802890406\n",
      "Client: client19\n",
      "Model client19 Train Epoch: 1 [0/1216 (0%)]\tLoss: 2.503906\n",
      "Model client19 Train Epoch: 2 [0/1216 (0%)]\tLoss: 2.072677\n",
      "Model client19 Train Epoch: 3 [0/1216 (0%)]\tLoss: 1.569839\n",
      "Model client19 Train Epoch: 4 [0/1216 (0%)]\tLoss: 1.357729\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7d10baa9b189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_members\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mgoodchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mClientUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msnrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcsis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmallmu1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoodchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5c5e6a838d4a>\u001b[0m in \u001b[0;36mClientUpdate\u001b[0;34m(args, device, client, key_np, key, snr, csi, mu, head)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m#considering the client model for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hook'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hook'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CWFL/Dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for client in clients: #give the model and optimizer to every client\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    #client['model'] = torch.quantization.quantize_dynamic(\n",
    "    #client['model'],  # the original model\n",
    "    #{torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "    #dtype=torch.fp)  # the target dtype for quantized weights\n",
    "    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr)\n",
    "\n",
    "final_acc=[]\n",
    "final_loss=[]\n",
    "clor = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(args.numclusters)]   \n",
    "for fed_round in range(args.rounds):\n",
    "    overall=Net()\n",
    "    if(fed_round==0): #fed_round==0\n",
    "        arranged_clusters,head_snr_list=cluster_former(args.numclusters,args.clients)\n",
    "        temp=deepcopy(arranged_clusters)\n",
    "        temp2=deepcopy(head_snr_list)\n",
    "    else:\n",
    "        #print(temp)\n",
    "        arranged_clusters=deepcopy(temp)\n",
    "        head_snr_list=deepcopy(temp2)\n",
    "#     print(arranged_clusters)\n",
    "    \n",
    "    no=1\n",
    "    heads_list=[]\n",
    "    weights=[]\n",
    "    weight_head_list=[]\n",
    "    head_acc=[]\n",
    "    head_loss=[]\n",
    "    for cluster in arranged_clusters:\n",
    "        \n",
    "        head=cluster['Cluster Head']\n",
    "        members=cluster['Members']\n",
    "        snrs=cluster['SNR']\n",
    "        csis=cluster['CSI']\n",
    "        weights.append(sum(snrs))\n",
    "        weight_head_list.append([head,sum(snrs)])\n",
    "        new_members=[]\n",
    "        \n",
    "        for ij in members:\n",
    "        #print(ij)\n",
    "            cl_no=int(ij[6:])\n",
    "            new_members.append(clients[cl_no-1])\n",
    "#         print(head)\n",
    "        head=clients[int(head[6:])-1]\n",
    "        cluster['Members']=new_members\n",
    "#         print(head)\n",
    "\n",
    "        smallmu1=0\n",
    "        gsmall1=3.402823466E+38 \n",
    "        \n",
    "        #water filling algorithm\n",
    "        mu=1e-15\n",
    "        while(mu<=1):\n",
    "            g1=0\n",
    "            pn1=0\n",
    "            for jj in csis:\n",
    "                pn=max(1/mu-1/jj,0)\n",
    "                g1+=math.log(1+pn*jj) #capacity of a channel (shannon's law)\n",
    "                pn1+=pn\n",
    "            g=g1-mu*(pn1-P*30)\n",
    "            if(g<gsmall1):\n",
    "                smallmu1=mu\n",
    "                gsmall1=g\n",
    "            mu+=0.00002\n",
    "        \n",
    "        print(smallmu1)\n",
    "        good_mem=[]\n",
    "#         print(len(snrs))\n",
    "#         print(len(csis))\n",
    "#         print(len(new_members))\n",
    "        index=0\n",
    "        for client in new_members:\n",
    "            goodchannel=ClientUpdate(args, device, client,key_np,key,snrs[index],csis[index],smallmu1,head)\n",
    "            index+=1\n",
    "            if(goodchannel):\n",
    "                good_mem.append(client)\n",
    "        \n",
    "        head['model']=averageModels(head['model'], good_mem)\n",
    "        arr=test(args,head['model'], device, global_test_loader, 'Cluster'+str(no),fed_round)\n",
    "        ac=arr[0]#test(args,head['model'], device, global_test_loader, 'Cluster'+str(no),fed_round)[0]\n",
    "        no+=1\n",
    "        heads_list.append(head)\n",
    "        head_acc.append(ac)\n",
    "        head_loss.append(arr[1])#test(args,head['model'], device, global_test_loader, 'Cluster'+str(no),fed_round)[1])\n",
    "    \n",
    "    final_acc.append(head_acc)\n",
    "    final_loss.append(head_loss)\n",
    "    fig,ax=plt.subplots()\n",
    "    \n",
    "    #ax.plot([i for i in range(fed_round)],head_acc[0])\n",
    "    for jj in range(0,args.numclusters):\n",
    "        \n",
    "        ax.plot([i for i in range(len(final_acc))],[final_acc[j][jj] for j in range(len(final_acc))], color = clor[jj])\n",
    "        \n",
    "    #ax.plot([i for i in range(len(final_acc))],[final_acc[j][0] for j in range(len(final_acc))], color =\"red\")\n",
    "    #ax.plot([i for i in range(len(final_acc))],[final_acc[j][1] for j in range(len(final_acc))],color =\"blue\")\n",
    "    #ax.plot([i for i in range(len(final_acc))],[final_acc[j][2] for j in range(len(final_acc))],color =\"green\")\n",
    "    #ax.plot([i for i in range(len(final_acc))],[final_acc[j][3] for j in range(len(final_acc))],color =\"black\")\n",
    "    #ax.plot([i for i in range(len(final_acc))],head_acc[1], fed_round, color =\"blue\")\n",
    "    #ax.plot([i for i in range(len(final_acc))],head_acc[2], fed_round, color =\"green\")\n",
    "    #ax.plot([i for i in range(len(final_acc))],head_acc[3], fed_round, color =\"black\")\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    weightsum=sum(weights)\n",
    "    \n",
    "    weights[:] = [x / weightsum for x in weights]\n",
    "    for aah in range(len(weight_head_list)):\n",
    "        weight_head_list[aah][1]=weights[aah]\n",
    "    final_heads,nets=decentralized(heads_list,head_snr_list,weight_head_list)\n",
    "    \n",
    "    for head in range(len(final_heads)):\n",
    "        for cluster in arranged_clusters:\n",
    "            head1=cluster['Cluster Head']\n",
    "            if(head1==final_heads[head]['hook'].id):\n",
    "                for mem in cluster['Members']:\n",
    "                    mem['model'].load_state_dict(nets[head].state_dict())\n",
    "    print(\"ROUND\",fed_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FL",
   "language": "python",
   "name": "fl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
